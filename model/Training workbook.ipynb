{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a329471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "from model import LofiModel\n",
    "from config import *\n",
    "from train import train\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc35866",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43969ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LofiModel(\n",
      "  (encoder): Encoder(\n",
      "    (input_projection): Linear(in_features=36, out_features=128, bias=True)\n",
      "    (lstm): LSTM(128, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
      "    (fc_mu): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (fc_logvar): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  )\n",
      "  (decoder): HierarchicalDecoder(\n",
      "    (z_to_conductor_initial): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (conductor): LSTM(1, 512, num_layers=2, batch_first=True)\n",
      "    (conductor_to_decoder_initial): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (decoder_rnn): LSTM(1, 512, num_layers=2, batch_first=True)\n",
      "    (output_projection): Linear(in_features=512, out_features=108, bias=True)\n",
      "  )\n",
      ")\n",
      "Model has 18.45 M parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LofiModel()\n",
    "# model.load_weights(r\"C:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\PZ#2\\model\\checkpoints\\Modele LOFI\\lofi_model_epoch_320.pth\")\n",
    "print(model)\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters()) / 1e6:.2f} M parameters.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0bdafc",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cae3b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Loading dataset with sliding window...\n",
      "Found 1276 MIDI files.\n",
      "Processing MIDI files, normalizing tempo, and extracting segments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1276/1276 [02:42<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted 105286 segments from 1276 files.\n",
      "Dataset split into: Train=89493, Validation=15793\n",
      "Finished preparing dataset.\n",
      "\n",
      "Calculating class weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing dataset for weights: 100%|██████████| 2797/2797 [00:01<00:00, 1488.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated class weights: [0.019432129338383675, 0.4869954586029053, 0.4935724139213562]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch, sklearn.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/ziemmi13/lofi-vae/0df62c17dea84be9a488257266d990e7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "----- Starting training -----\n",
      "-----------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 [Training]: 100%|██████████| 2797/2797 [02:10<00:00, 21.44it/s, Loss=0.9132, Recon=0.9132, KL=1.2664, beta=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary: Avg Train Loss: 0.9736, Avg Val Loss: 1.0274\n",
      "\n",
      "Generating visualization for epoch 1:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMaestro dataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\PZ#2\\model\\train.py:147\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, early_stopping, experiment_name, verbose)\u001b[39m\n\u001b[32m    145\u001b[39m random_num = torch.randint(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(val_dataloader.dataset), (\u001b[32m1\u001b[39m,)).item()\n\u001b[32m    146\u001b[39m original_tensor = val_dataloader.dataset[random_num]\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m reconstructed_tensor = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, figsize=(\u001b[32m16\u001b[39m, \u001b[32m12\u001b[39m))\n\u001b[32m    150\u001b[39m fig.suptitle(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReconstruction at Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, fontsize=\u001b[32m20\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\PZ#2\\model\\model.py:172\u001b[39m, in \u001b[36mLofiModel.reconstruct\u001b[39m\u001b[34m(self, input_pianoroll, output_path)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28mself\u001b[39m.eval()\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     input_batch = \u001b[43minput_pianoroll\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m(\u001b[32m0\u001b[39m).to(device)\n\u001b[32m    173\u001b[39m     recon_logits, _, _ = \u001b[38;5;28mself\u001b[39m(input_batch)\n\u001b[32m    174\u001b[39m     reconstructed_pianoroll = torch.argmax(recon_logits, dim=-\u001b[32m1\u001b[39m).squeeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "train(model, experiment_name=\"Maestro dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
